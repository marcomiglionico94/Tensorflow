{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Using Keras\n",
    "Transfer learning, is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.\n",
    "\n",
    "<img src = \"./images/tf_idea.png\">\n",
    "\n",
    "In the context of Deep Learning there are 2 general ways to do tranfer learning:\n",
    "- **Feature Extraction**\n",
    "- **Fine Tuning**\n",
    "\n",
    "There are 4 main scenarios that you can find:\n",
    " - **1. New dataset is small and similar to original dataset:** There is a problem of over-fitting, if we try to train the entire network. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
    " - **2. New dataset is large and similar to the original dataset:** Since we have more data, we can have more confidence that we won’t overfit if we were to try to fine-tune through the full network.\n",
    " - **3. New dataset is small but very different from the original dataset:** Since the dataset is very small, We may want to extract the features from the earlier layer and train a classifier on top of that\n",
    " - **4. New dataset is large and very different from the original dataset:** This is straight forward. since you have large dataset, you can design your own network or use the existing ones. You can use the pretrained weights as weights initialization if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tranfer Learning via Feature Extraction\n",
    "When performing feature extraction, we treat the pre-trained network as an arbitrary feature extractor, allowing the input image to propagate forward, stopping at pre-specified layer, and taking the outputs of that layer as our features.\n",
    "The key idea here is to just leverage the pre-trained model’s weighted layers to extract features but not to update the weights of the model’s layers during training with new data for the new task.\n",
    "\n",
    "<img src=\"./images/transfer2.png\">\n",
    "\n",
    "For instance, if we utilize AlexNet without its final classification layer, it will help us transform images from a new domain task into a 4096-dimensional vector based on its hidden states, thus enabling us to extract features from a new domain task, utilizing the knowledge from a source-domain task. This is one of the most widely utilized methods of performing transfer learning using deep neural networks.\n",
    "\n",
    "The 2 most common machine learning models you will see for Transfer Learning are **SVM** and **Logistic Regression**. One of the main reason is that the extracted feature vector tends to be very large and have a high dimensionality. For this reason we need a linear model that can train fast on top of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we’ll use is the Food-5K dataset(https://mmspg.epfl.ch/downloads/food-image-datasets/) curated by the Multimedia Signal Processing Group (MSPG) of the Swiss Federal Institute of Technology.\n",
    "\n",
    "The dataset, as the name suggests, consists of 5,000 images, belonging to two classes:\n",
    "\n",
    "- **Food**\n",
    "- **Non-food**\n",
    "\n",
    "<img src=\"./images/food5K.png\">\n",
    "\n",
    "Our goal of is to train a classifier such that we can distinguish between these two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from pyimagesearch import config\n",
    "#from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 16s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network and initialize the label encoder\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "le = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
